<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />

    <link rel="stylesheet" href="styles.css" />
    <title>Face Detection Demo</title>
  </head>

  <body>
    <div class="centered" style="margin-top: 20px; margin-bottom: 20px">
      <h1 class="title">Face Detection Demo</h1>
      <ul>
        There are many versions for socket.io, using specificly as used in this
        one else will get lot of errors
        <br />
        cdnjs I used,
        http://cdnjs.cloudflare.com/ajax/libs/socket.io/1.3.6/socket.io.min.js
        <br />
        maybe use using npm instead of this
        <hr />
        In most cases server will listen on detect* and send on detected*
        <br />
        Example:<br />
        objectDetection: send to detectObject, and recieve on detectedObject
        <br />
        anprDetection: send to detectAnpr, and recieve on detectedAnpr
        <br />
        <hr />
        Need to take care of cleaning up the frames, when recieve no data
        <hr />
      </ul>
    </div>

    <div class="centered">
      <canvas id="bb_canvas"></canvas>
      <video autoplay controls id="videoElement">
        <source src="./anpr.mp4" type="video/mp4" />
      </video>
      <br />
      <hr />
      <button onclick="playVideo()" type="button">Play</button>
      <button onclick="pauseVideo()" type="button">Pause</button><br />
    </div>

    <div>
      <ul id="backendList"></ul>
    </div>

    <script
      type="text/javascript"
      src="http://cdnjs.cloudflare.com/ajax/libs/socket.io/1.3.6/socket.io.min.js"
    ></script>

    <script>
      var video = document.getElementById('videoElement')
      /*
        //uncomment this section to use webcam

        if (navigator.mediaDevices.getUserMedia) {
          navigator.mediaDevices
            .getUserMedia({ video: true })
            .then(function (stream) {
              video.srcObject = stream
            })
            .catch(function (error) {
              console.log('Something went wrong!')
            })
        }
      */

      // will have no use in actual app, just for testing purposes
      function playVideo() {
        video.play()
      }
      function pauseVideo() {
        video.pause()
      }

      // server URL and connect to server
      var server_url = 'http://www.mrexy.com:5000'
      var socket = io.connect(server_url)

      // you will recieve data on this end point, manupliate accordingly using canvas
      socket.on('detectedAnpr', function (data) {
        console.log('Detected a plate...')
        console.log(data)

        var canvas = document.getElementById('bb_canvas')
        var cw = canvas.width
        var ch = canvas.height
        canvas.width = 0
        canvas.height = 0
        canvas.width = cw
        canvas.height = ch
        var w_fact = canvas.width / canvas.offsetWidth
        var h_fact = canvas.height / canvas.offsetHeight
        ctx = canvas.getContext('2d')
        console.log('data.faces:=>', typeof data.faces)
        console.log('data:=>', typeof data)

        if (data.liscence) {
          var node = document.createElement('LI') // Create a <li> node
          var textnode = document.createTextNode(
            data.liscence + ' registered: ' + data.registered
          ) // Create a text node
          node.appendChild(textnode) // Append the text to <li>
          document.getElementById('backendList').appendChild(node) // Append <li> to <ul> with id="myList"
        }

        /*
          data = []

        */
        // data printing manuplation stuff

        // something similar thing needs to be done
        // just loop through the array you are getting
        // and display the data accordingly
        // like making bounding boxes as below
        // rn it is not working(may be I am looping incorrectly)
        // just rectify it in JS

        /*
        for (data in data.faces) {
          console.log('data=>', data)
          ctx.strokeStyle = data['color']
          ctx.rect(
            data['x'] * w_fact,
            data['y'] * h_fact,
            data['w'] * w_fact,
            data['h'] * h_fact
          )
          ctx.stroke()
          ctx.fillText(data['text'], 10, 50)
        }
        */
        // playing video feed in frontend
      })

      // convert image to blob (will be same for most of the thing)
      function dataURLtoBlob(dataURL) {
        var binary = atob(dataURL.split(',')[1])
        var array = []
        for (var i = 0; i < binary.length; i++) {
          array.push(binary.charCodeAt(i))
        }
        return new Blob([new Uint8Array(array)], { type: 'image/png' })
      }

      // capture the video frame
      function captureImage() {
        var video = document.getElementById('videoElement')

        var canvas = document.createElement('canvas')
        canvas.width = video.offsetWidth
        canvas.height = video.offsetHeight
        canvas
          .getContext('2d')
          .drawImage(video, 0, 0, canvas.width, canvas.height)
        var data_url = canvas.toDataURL()

        return data_url
      }

      // main function to get video frame, convert it to blob, and send it to the server for processing
      function main() {
        console.log('Capturing and sending ...')
        var data_url = captureImage()
        var image_blob = dataURLtoBlob(data_url)
        socket.emit('detectAnpr', { data: image_blob })
      }

      // after every 800ms send frame to server
      // adjust it accordingly(depending on latency you are geting)
      // frame by frame video send after every 800ms
      setInterval(main, 800)
    </script>
  </body>
</html>
